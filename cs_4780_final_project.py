# -*- coding: utf-8 -*-
"""CS_4780_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/187EC_atz6fLE-aoJIhy1_cZst8Uqbdf3

<h2>CS 4780/5780 Final Project: </h2>
<h3>Election Result Prediction for US Counties</h3>

Names and NetIDs for your group members: Michael Guan(mhg99), Enoch Kim (ek537), Ashrafur Siddiqui (as3273)

<h3>Introduction:</h3>

<p> The final project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The programming project provide templates for how to do this, and the most recent video lectures summarize some of the tricks you will need (e.g. feature normalization, feature construction). So, this final project brings realism to how you will use machine learning in the real world.  </p>

The task you will work on is forecasting election results. Economic and sociological factors have been widely used when making predictions on the voting results of US elections. Economic and sociological factors vary a lot among counties in the United States. In addition, as you may observe from the election map of recent elections, neighbor counties show similar patterns in terms of the voting results. In this project you will bring the power of machine learning to make predictions for the county-level election results using Economic and sociological factors and the geographic structure of US counties. </p>
<p>

<h3>Your Task:</h3>
Plase read the project description PDF file carefully and make sure you write your code and answers to all the questions in this Jupyter Notebook. Your answers to the questions are a large portion of your grade for this final project. Please import the packages in this notebook and cite any references you used as mentioned in the project description. You need to print this entire Jupyter Notebook as a PDF file and submit to Gradescope and also submit the ipynb runnable version to Canvas for us to run.

<h3>Due Date:</h3>
The final project dataset and template jupyter notebook will be due on <strong>December 15th</strong> . Note that <strong>no late submissions will be accepted</strong>  and you cannot use any of your unused slip days before.
</p>

![image.png; width="100";](attachment:image.png)

<h2>Part 1: Basics</h2><p>

<h3>1.1 Import:</h3><p>
Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:
    
https://scikit-learn.org/stable/tutorial/basic/tutorial.html
    
https://pytorch.org/tutorials/
    
https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html
<p>
"""

import os
import pandas as pd
import numpy as np
# TODO
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV


import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# tqdm gives us nice progress bars, which provide a huge quality-of-life boost,
# so it's worth mentioning here.
from tqdm import tqdm

"""<h3>1.2 Weighted Accuracy:</h3><p>
Since our dataset labels are heavily biased, you need to use the following function to compute weighted accuracy throughout your training and validation process and we use this for testing on Kaggle.
<p>
"""

def weighted_accuracy(pred, true):
    assert(len(pred) == len(true))
    num_labels = len(true)
    num_pos = sum(true)
    num_neg = num_labels - num_pos
    frac_pos = num_pos/num_labels
    weight_pos = 1/frac_pos
    weight_neg = 1/(1-frac_pos)
    num_pos_correct = 0
    num_neg_correct = 0
    for pred_i, true_i in zip(pred, true):
        num_pos_correct += (pred_i == true_i and true_i == 1)
        num_neg_correct += (pred_i == true_i and true_i == 0)
    weighted_accuracy = ((weight_pos * num_pos_correct) 
                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))
    return weighted_accuracy

"""<h2>Part 2: Baseline Solution</h2><p>
Note that your code should be commented well and in part 2.4 you can refer to your comments. (e.g. # Here is SVM, 
# Here is validation for SVM, etc). Also, we recommend that you do not to use 2012 dataset and the graph dataset to reach the baseline accuracy for 68% in this part, a basic solution with only 2016 dataset and reasonable model selection will be enough, it will be great if you explore thee graph and possibly 2012 dataset in Part 3.

<h3>2.1 Preprocessing and Feature Extraction:</h3><p>
Given the training dataset and graph information, you need to correctly preprocess the dataset (e.g. feature normalization). For baseline solution in this part, you might not need to introduce extra features to reach the baseline test accuracy.
<p>
"""

# You may change this but we suggest loading data with the following code and you may need to change
# datatypes and do necessary data transformation after loading the raw data to the dataframe.
# df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')

# Make sure you comment your code clearly and you may refer to these comments in the part 2.4
# TODO
dataset_path = "/content/train_2016.csv"
df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')

# FIPS and County represent the "same" data, only need FIPS here
df_clean = df.drop(1, axis=1)

#Removed the headers from the data
df_clean = df_clean.drop(0, axis=0)

#Change the type from string (remove comma) to float
df_clean = df_clean.apply(lambda x: x.str.replace(',', '').astype(np.double), axis=1)

#Get y values GOP: 0, DEM: 1 
y = df_clean[2] > df_clean[3] 
y = y.astype(int)

#Remove the votes
df_clean = df_clean.drop(2, axis=1)
df_clean = df_clean.drop(3, axis=1)

def normalize(df, mean, std):
    # x = df.values #returns a numpy array
    # #Transforms each colums of x on a 0-1 scale
    # min_max_scaler = preprocessing.MinMaxScaler() 
    # x_scaled = min_max_scaler.fit_transform(x)
    return (df.to_numpy()-mean)/std

mean = df_clean.mean().to_numpy()
std = df_clean.std().to_numpy()

df_norm = normalize(df_clean, mean, std)
df_norm_f = normalize(df_clean.drop(0, axis=1), mean[1:], std[1:])

def prep(path, mean, std):
    #This is for the actual test data (we get the DEM and GOP numbers in train)
    dataset_path = path
    df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')
    # print(df)
    df_clean = df.drop(1, axis=1)
    df_clean = df_clean.drop(0, axis=0)
    df_clean = df_clean.apply(lambda x: x.str.replace(',', '').astype(float), axis=1)
    # print(df_clean)
    df_norm = normalize(df_clean, mean, std)
    # print("regnorm")
    df_norm_f = normalize(df_clean.drop(0, axis=1), mean[1:], std[1:])
    return df.to_numpy(), df_clean.to_numpy(), df_norm, df_norm_f

"""<h3>2.2 Use At Least Two Training Algorithms from class:</h3><p>
You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 1.1.
"""

# Make sure you comment your code clearly and you may refer to these comments in the part 2.4


#Algorithm 1: SVM
clf_svm = svm.SVC(kernel='rbf') 
clf_svm_f = svm.SVC(kernel='rbf') 
#Algorithm 2: Bayes
clf_bayes = GaussianNB()
clf_bayes_f = GaussianNB()

"""<h3>2.3 Training, Validation and Model Selection:</h3><p>
You need to split your data to a training set and validation set or performing a cross-validation for model selection.
"""

# Make sure you comment your code clearly and you may refer to these comments in the part 2.4
# TODO

x_train, x_test, y_train, y_test = train_test_split(df_norm, y, test_size=0.2, random_state=42)

#no fips
x_train_f, x_test_f, y_train_f, y_test_f = train_test_split(df_norm_f, y, test_size=0.2, random_state=42)
# x_train_f = x_train_f.to_numpy()
y_train_f = y_train_f.to_numpy()
# x_test_f = x_test_f.to_numpy()
y_test_f = y_test_f.to_numpy()

#Split train and test
#Kfold on train
#double for loop for C value optimization
#train on C* eval on test

kf = KFold(n_splits=6)
Cstar = 1
Cscore = 0
for c in range(3500,3505,1):
  # print(c)
  score = 0
  count = 0
  for train_index, test_index in kf.split(x_train_f):
      x_train_k, x_test_k = x_train_f[train_index],  x_train_f[test_index]
      y_train_k, y_test_k = y_train_f[train_index],  y_train_f[test_index]
      clf_svm_k = svm.SVC(kernel='rbf', C=c) 
      clf_svm_k.fit(x_train_k, y_train_k)
      y_pred = clf_svm_k.predict(x_test_k)
      score += weighted_accuracy(y_pred, y_test_k)
      count += 1
  score = score/count
  if (score > Cscore):
      # print("better c value", c, Cstar)
      Cstar = c
      Cscore = score
#print("C*: ", Cstar, Cscore)
clf_svm_k = svm.SVC(kernel='rbf', C=Cstar) 
clf_svm_k.fit(x_train_f, y_train_f)
y_pred = clf_svm_k.predict(x_test_f)

#print("(No FIPS) K-fold SVM Accuracy:",weighted_accuracy(y_pred, y_test_f))

clf_svm_f.fit(x_train_f, y_train_f)
y_pred = clf_svm_f.predict(x_test_f)

#print("(No FIPS) SVM Accuracy:",weighted_accuracy(y_pred, y_test_f))

clf_bayes_f.fit(x_train_f, y_train_f)
y_pred = clf_bayes_f.predict(x_test_f)

#print("(No FIPS) Bayes Accuracy:",weighted_accuracy(y_pred, y_test_f))

clf_svm.fit(x_train, y_train)
y_pred = clf_svm.predict(x_test)

#print("(FIPS) SVM Accuracy:",weighted_accuracy(y_pred, y_test))

clf_bayes.fit(x_train, y_train)
y_pred = clf_bayes.predict(x_test)



#print("(FIPS) Bayes Accuracy:",weighted_accuracy(y_pred, y_test))

"""
(No FIPS) K-fold SVM Accuracy: 0.7247412008281574
(No FIPS) SVM Accuracy: 0.5659937888198757
(No FIPS) Bayes Accuracy: 0.6782608695652174
(FIPS) SVM Accuracy: 0.5659937888198757
(FIPS) Bayes Accuracy: 0.6639751552795031
"""

"""<h3>2.4 Explanation in Words:</h3><p>
    You need to answer the following questions in the markdown cell after this cell:

2.4.1 How did you preprocess the dataset and features?

2.4.2 Which two learning methods from class did you choose and why did you made the choices?

2.4.3 How did you do the model selection?

2.4.4 Does the test performance reach a given baseline 68% performance? (Please include a screenshot of Kaggle Submission)

2.4.1 How did you preprocess the dataset and features?

We first got rid of sections of the training data we decided should not be on a Training vector. This included FIPS and County. The identification number and county name should have no correlation to the votes. We also removed Dem and GOP columns and converted them into our y values, 0 means Dem win and 1 for GOP win. We also had to convert the numbers from strings into numeric values. This meant we had to remove the commas. We then normalized the data from 0 to 1 to make numbers mean something relative to the other data. 
 
2.4.2 Which two learning methods from class did you choose and why did you make the choices?

We chose a Kernelized SVM because we thought that it would perform well with the data given to us. We hoped that in some dimension it would be separable. We then did a Naive Bayes training algorithm. We chose this because we thought that certain features such as median income, bachelor rate and unemployment rate would have more drastic effects on the outcome of the county. For example, High Bachelor rate may imply a more college graduates which have shown to vote more democratic in recent studies.
 
2.4.3 How did you do the model selection?

We split the data into a training set and a validation set. We then performed K-fold cross validation where there were 6 splits so that there was enough data to train on. We also optimized the C value for our SVM function.
 
2.4.4 Does the test performance reach a given baseline 68% performance? (Please include a screenshot of Kaggle Submission)
 
Yes it does.
![131205991_423011085393024_5194647251442065452_n.png](data:image/png;base64,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)

<h2>Part 3: Creative Solution</h2><p>

<h3>3.1 Open-ended Code:</h3><p>
You may follow the steps in part 2 again but making innovative changes like creating new features, using new training algorithms, etc. Make sure you explain everything clearly in part 3.2. Note that reaching the 75% creative baseline is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained.
"""

import os
import pandas as pd
import numpy as np
# TODO
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
from sklearn.model_selection import KFold

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# tqdm gives us nice progress bars, which provide a huge quality-of-life boost,
# so it's worth mentioning here.
from tqdm import tqdm
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
def weighted_accuracy(pred, true):
    assert(len(pred) == len(true))
    num_labels = len(true)
    num_pos = sum(true)
    num_neg = num_labels - num_pos
    frac_pos = num_pos/num_labels
    weight_pos = 1/frac_pos
    weight_neg = 1/(1-frac_pos)
    num_pos_correct = 0
    num_neg_correct = 0
    for pred_i, true_i in zip(pred, true):
        num_pos_correct += (pred_i == true_i and true_i == 1)
        num_neg_correct += (pred_i == true_i and true_i == 0)
    weighted_accuracy = ((weight_pos * num_pos_correct) 
                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))
    return weighted_accuracy
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
# You may change this but we suggest loading data with the following code and you may need to change
# datatypes and do necessary data transformation after loading the raw data to the dataframe.
# df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')

# Make sure you comment your code clearly and you may refer to these comments in the part 2.4
# TODO
#dataset_path = "/content/train_2016.csv"
dataset_path = "/content/train_2016.csv"
dataset_path2 = "/content/train_2012.csv"
dataset_path3 = "/content/test_2016_no_label.csv"
df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')
#df2 = pd.read_csv(dataset_path2, sep=',',header=None, encoding='unicode_escape')
#df2 = df2.drop(0, axis = 0)
#df = df.append(df2)

# FIPS and County represent the "same" data, only need FIPS here
df_clean = df.drop(1, axis=1)

#Removed the headers from the data
df_clean = df_clean.drop(0, axis=0)

#Change the type from string (remove comma) to float
df_clean = df_clean.apply(lambda x: x.str.replace(',', '').astype(np.double), axis=1)

#Get y values GOP: 0, DEM: 1 
y = df_clean[2] > df_clean[3] 
y = y.astype(int)

#Remove the votes
df_clean = df_clean.drop(2, axis=1)
df_clean = df_clean.drop(3, axis=1)

#Add Features
df_clean[10] = df_clean[5] + df_clean[6] + df_clean[7] #Population Change
df_clean[11] = df_clean[8]/df_clean[9] #Ratio of Edu to Unemployment
df_clean[12] = df_clean[10]*df_clean[4] # Pop change * Median
df_clean[13] = df_clean[11]*df_clean[4] # Edu/unemplyment * Median 
df_clean[14] = df_clean[10]*df_clean[11] #Ratio among new population


def normalize(df, mean, std):
    return (df.to_numpy()-mean)/std

mean = df_clean.mean().to_numpy()
std = df_clean.std().to_numpy()


df_norm = normalize(df_clean, mean, std)
df_norm_f = normalize(df_clean.drop(0, axis=1), mean[1:], std[1:])

def prep(path, mean, std):
    #This is for the actual test data (we get the DEM and GOP numbers in train)
    dataset_path = path
    df = pd.read_csv(dataset_path, sep=',',header=None, encoding='unicode_escape')
    df_clean = df.drop(1, axis=1)
    df_clean = df_clean.drop(0, axis=0)
    df_clean = df_clean.apply(lambda x: x.str.replace(',', '').astype(float), axis=1)
    
    #Add Features
    df_clean[8] = df_clean[3] + df_clean[4] + df_clean[5]
    df_clean[9] = df_clean[6]/df_clean[7]
    df_clean[10] = df_clean[8]*df_clean[2]
    df_clean[11] = df_clean[9]*df_clean[2]
    df_clean[12] = df_clean[8]*df_clean[9]


    df_norm = normalize(df_clean, mean, std)
    df_norm_f = normalize(df_clean.drop(0, axis=1), mean[1:], std[1:])
    return df.to_numpy(), df_clean.to_numpy(), df_norm, df_norm_f


#print("DATA PREPED")


#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------

#Use no FIPS
x_train, x_test, y_train, y_test = train_test_split(df_norm_f, y, test_size=0.2, random_state=42)

y_train = y_train.to_numpy()
y_test = y_test.to_numpy()
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------

"""
Three step process for machine learning, ignoring a bunch of important things
we talked about in class:

1. Get data
    1.1 Get a Dataset---this is provided by PyTorch
    1.2 Get a DataLoader---this is provided by PyTorch
2. Get a classifier, and other paraphenalia needed for training
    2.1 Create a classifier architecture, and instantiate it
    2.2 Get a criterion (loss function)
    2.3 Get an optimizer (thing that does parameter updates to the classifier)
3. Classify the data in some reasonably intelligent fashion. This will involve:
    3.1 A one_epoch() function that trains the classifier for one epoch---a
        complete iteration over the dataset from (1.1)
    3.2 A loop that calls one_epoch() the number of times we want to run an
        epoch.
4. ...
5. $$$
"""

# 'something_from_torch = something_from_torch.to(device)' puts the thing onto
# the device. If you have CUDA available, this will massively speed
# computations. Note that all inputs to a computation must be on the same
# device, and that things are on the CPU by default.
device = "cuda" if torch.cuda.is_available() else "cpu"

# Setting a random seed means we can reproduce our results easily. In my
# understanding, this is generally good practice.
np.random.seed(4780)
torch.manual_seed(4780)

# Here I define a bunch of constants that'll be needed later on. I've chosen the
# first two arbitrarily; the last three are set to values that are probably
# decent across a wide range of tasks.
input_dim = 11          # This is the dimensionality of the inputs X
output_dim = 2         # This is the number of classes in Y
num_workers = 4         # We want to parallelize loading data during training.
                        #   Otherwise, it's possible for moving data to model to
                        #   become a bottleneck in performance!
batch_size = 16        # This is the number of examples (x,y) that are run
                        #   through the neural net simultaneously. Think of it as
                        #   a mid-ground between SGD and GD.
num_epochs = 100       # The number of complete iterations over the dataset
                        #   made during training

save_file = "best_model.pt" # It's helpful to save the best-performing model
                            #   throughout training...

# 1.1---get the Dataset. A Dataset should extend PyTorch's base class, and needs
# to do two things:
# a) implement the __getitem__() method. This takes in an index to the data and
#       returns the x- and y-values of the ith datapoint, often as tensors.
# b) implement the __len__() method. This is just the amount of data in the
#       dataset.
class CountyDataset(Dataset):
    """An example dataset."""
    
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __getitem__(self, i):
        return torch.tensor(self.x[i]).float(), torch.tensor(np.array(self.y[i])).long()

    def __len__(self):
        return len(self.x)

        

train_dataset = CountyDataset(x_train, y_train)


val_dataset = CountyDataset(x_test, y_test)
val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)


# 1.2---get a DataLoader. This wraps a Dataset and allows you to iterate through
# it. It's also where you can implement *a lot* of performance optimizations.
# 'shuffle=True' is set by default, but it's worth emphasizing here.
#
# As long as values for 'batch_size' are reasonable (4 <= x << amount of data),
# changing it will mostly change the speed and not performance of the model.
# 'num_workers' should be just under your number of CPUs.
train_loader = DataLoader(train_dataset,
    shuffle=True,
    batch_size=batch_size,
    num_workers=num_workers)
    
# 2.1---here we define the actual neural net! It should be a class that inherits
# from torch.nn.Module, and has a forward() method that implements the function
#
#       f : X -> Y
#
# Because the neural net is *literally* a function, I'll call its outputs on an
# input 'x' 'fx'.
class NeuralNet(nn.Module):
    
    # As you know, a neural net is composed of layers. The first layer takes in
    # an example x, does a computation on it, and passes the result fx to the
    # second layer, and this process continues.
    #
    # Note that the architecture below illustrates how to build a neural net,
    # but shouldn't work too well otherwise.
    def __init__(self, input_dim, output_dim):
        super(NeuralNet, self).__init__()
        self.f1 = nn.Linear(input_dim , 4) 
        self.r1 = nn.ReLU()  
        self.f2 = nn.Linear(4, 5)
        self.r2 = nn.ReLU()  
        self.f3 = nn.Linear(5, 2)
        self.r3 = nn.ReLU()          
        self.fc = nn.Linear(2, output_dim)  
                                            
    # Don't worry about adding an activation function at the end. It's done
    # automatically in the loss function! Of course, this means the outputs of
    # the model need to be softmaxed before they can be used as probabilities.
    
    # This is the function that implements f : X -> Y. Note that we can expand
    # it as fc(r1(f1(x)))))!
    def forward(self, x):
        fx = self.f1(x)
        fx = self.r1(fx)
        fx = self.f2(fx)
        fx = self.r2(fx)
        fx = self.f3(fx)
        fx = self.r3(fx)
        return self.fc(fx)
        
# Instantiate the model! We need to move it to whatever device it'll be running
# on before we instantiate the optimizer in 2.3.
model = NeuralNet(input_dim, output_dim).to(device)

# 2.2---The criterion is the loss function. Normally, you use CrossEntropy for a
# classification task. (Binary classification is a special case where you can
# get away with doing something else like 0-1 loss.)
criterion = nn.CrossEntropyLoss()

# 2.3---The optimizer takes care of the parameter updates via its step() method.
# To make it work, we need to pass in the 'parameters' of the model. Generally,
# you'll choose between Adam and SGD.
optimizer = optim.Adam(model.parameters(), lr = .01)

# 3.1---I find it's useful to define a function implementing a single epoch, and
# then call it repeatedly from within a loop to train the neural net.
def one_epoch(model, train_loader, optimizer, criterion):
    """Returns [model] after being trained for one epoch on [data_loader] using
    [optimizer] and [criterion].
    """
    # [data_loader] returns batches of paired x- and y-values when we iterate
    # over it. Because of PyTorch magic, we don't have to worry about the batch
    # size!
    #
    # What is tqdm doing here? When we wrap an iterable in tqdm() during
    # iteration, we get a super nice progress bar!
    for x,y in tqdm(train_loader, desc="Running batches...", leave=False):
        # x is a tensor of dimension (batch_size x n_features), y is a tensor of
        # dimension (batch_size,). If they're not on the same device as [model],
        # they need to be moved there. (Note that it might be smarter to
        # accomplish this through the DataLoader.)
        x, y = x.to(device), y.to(device)
        
        optimizer.zero_grad()   # We only want to accumulate the gradient for
                                #   the current batch. Therefore, we zero out
                                #   the gradient of the model.
        fx = model(x.float())           # Compute predictions for a batch 'x'
        torch.flatten(y)
        loss = criterion(fx, y) # Compute the loss function's value on the
                                #   outputs of the model on 'x' and the true
                                #   labels 'y'
        loss.backward()         # Compute the gradients of the model's weights
                                #   with respect to the loss.
        optimizer.step()        # Update parameters by taking an intelligent
                                #   optimizer-determined step against the
                                #   gradient.
        
    # When the epoch is over, return the model.
    return model

# We can keep track of when after an epoch finishes our model has a better
# validation accuracy than anything else using this. We'll also need a function
# to compute validation accuracy!
best_val_acc = float("-inf")

def validate(model, val_loader):
    """Returns the accuracy of [model] on [val_loader]."""
    
    def batch_acc(x, y):
        """Returns the number of correct predictions of [model] on [x] given
        [y].
        """
        # Note that PyTorch can do most things that NumPy can. model(x) returns
        # a batch of predictions as a (batch_size x n_classes) tensor; y is a
        # (n_examples,) tensor of in which the i^th index contains the class of
        # the i^th example, eg. 5.
        #
        # Additionally, [model] is on [device], so you'll need to move [x] to
        # the device prior to computation. To move a tensor [t] to the CPU you
        # can call 't.cpu()'---this might be useful for comparing with [y].
        #
        # Can you fit this all on one line?
        # print("YOOOOOOO", np.argmax(model(x).numpy(), axis=1) == y.numpy())
        return np.sum(np.argmax(model(x).numpy(), axis=1) == y.numpy())
    
    # The length of a Dataset is the number of examples in it; the length of a
    # DataLoader is the number of batches. Therefore, to get the accuracy, it's
    # critical to divide by the length of the first and not the second!
    #
    # We can use NumPy here because it's generally (in my experience) faster for
    # things on the CPU than PyTorch.
    # print("Poggers")
    # print(np.sum([batch_acc(x, y) for x,y in val_loader]))
    # print(len(val_dataset))
    return np.sum([batch_acc(x, y) for x,y in val_loader]) / len(val_dataset)

# 3.2---Train the model on the entirety of the data once for every desired
# epoch. tqdm gives a nice progress bar.
for e in tqdm(range(num_epochs), desc="Running epochs..."):
    model = one_epoch(model, train_loader, optimizer, criterion)
    
    # Suppose we wanted to find the validation accuracy after epoch! All we'd
    # need would be a validation DataLoader, and a function to get accuracy
    # from! Putting this under 'with torch.no_grad():' turns off computing
    # gradients, because we don't need them. Moreover, wrapping it in
    # 'model.eval()' and 'model.train()' is important if we do fancy things like
    # dropout.
    with torch.no_grad():
        model.eval()
        val_acc = validate(model, val_loader)
        model.train()
    
    # When in the middle of a tqdm-ed loop, we need to use 'tqdm.write()'
    # instead of 'print()'.
    tqdm.write(f"Epoch {e:3} | validation accuracy: {val_acc}")
    
    # If the validation accuracy is the highest it's ever been, why not save the
    # the model? This is a natural way to figure out the correct number of
    # epochs!
    if val_acc > best_val_acc:
        tqdm.write(f"------Best epoch yet with accuracy {val_acc}. Saved!")
        best_val_acc = val_acc
        
        # Saving a PyTorch model is super easy! 'model.state_dict()' converts
        # all of its weights to a dictionary format. The general format here is
        # 'torch.save(dictionary, file)'. Note that we can put basically
        # anything we want in this dictionary too!
        torch.save(model.state_dict(), save_file)
        
# Now that training is done, let's load the best model so we can do something
# with it. First, we need to instantiate a new model of the same type as the
# old one. Then we can call 'load_state_dict()' on the loaded state_dict.
model = NeuralNet(input_dim, output_dim)
best_val_acc_model_weights = torch.load(save_file)
model.load_state_dict(best_val_acc_model_weights)

################################################################################
### WANT TO SEE THE CODE RUN? PASTE THE FOLLOWING CODE DIRECTLY ABOVE 1.2, THEN
### IMPLEMENT 'batch_acc()'.
### It's way beyond the scope of the course though still far too simple for the
### task it takes on; I use it to validate what I've written elsewhere. Also
### note that it downloads the MNIST (handwritten images) dataset to your
### computer, so beware...though you really can just delete it later.
###
### Aside: you should be able to get at least 95% accuracy on the MNIST dataset
### without trying. This gets up to about 70% accuracy because I deliberately
### wrote the worst neural net I could think of that'd illustrate what I needed
### to show.
################################################################################
# import torchvision
# from torchvision import transforms
# from torch.utils.data import Subset
# transform = transforms.Compose([
#     transforms.ToTensor(),
#     transforms.Lambda(lambda t: torch.flatten(t)),
# ])
# dataset = torchvision.datasets.MNIST("./MNIST/",
#     train=True, transform=transform, download=True)
# train_dataset = Subset(dataset, range(0, 10000))
# val_dataset = Subset(dataset, range(10000, 11000))
# val_loader = DataLoader(val_dataset, batch_size=64, num_workers=4)
# input_dim, output_dim, num_epochs = 784, 10, 100

"""<h3>3.2 Explanation in Words:</h3><p>

You need to answer the following questions in a markdown cell after this cell:

3.2.1 How much did you manage to improve performance on the test set compared to part 2? Did you reach the 75% accuracy for the test in Kaggle? (Please include a screenshot of Kaggle Submission)

3.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this.

3.2.1 

![image.png](data:image/png;base64,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)

3.2.2 We changed our machine learning algorithm to a neural network. We had also added 5 new features that we believed could provide some useful information. We calculated the Population rate of change since counties with more people entering could indicate a growing younger population/families where young people and women tend to vote democratic. Bachelor's degree to unemployment ratio since this could indicate a higher educated population, and especially young people without jobs but with bachelor's degrees. An estimate on total population income per year a rough estimate to calculate whether there are many high-paying jobs and less of a blue-collar working county. The ratio of educated to unemployed relative multiplied by the median income since this could suggest how much bachelors impact the median income suggesting either a low skilled work. Finally, we included a change in the ratio among the newly educated population which could suggest again of new and younger people entering a county which I have previously mentioned.

<h2>Part 4: Kaggle Submission</h2><p>
You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The CSV shall contain TWO column named exactly "FIPS" and "Result" and 1555 total rows excluding the column names, "FIPS" column shall contain FIPS of counties with same order as in the test_2016_no_label.csv while "Result" column shall contain the 0 or 1 prdicaitons for corresponding columns. A sample predication file can be downloaded from Kaggle.
"""

# TODO

# You may use pandas to generate a dataframe with FIPS and your predictions first 
# and then use to_csv to generate a CSV file.

#model_to_use = clf_svm_k
#model_to_use.fit(df_norm, y)

best_val_acc_model_weights = torch.load(save_file)
model.load_state_dict(best_val_acc_model_weights)

y_pred = np.argmax(model(torch.tensor(x_test).float()).detach().numpy(), axis=1)
print("NN:",weighted_accuracy(y_pred, y_test_f))


df_t, df_t_clean, df_t_norm, df_t_norm_f = prep("/content/test_2016_no_label.csv", mean, std)


#y_submit = model_to_use.predict(df_t_norm_f)

y_s = model(torch.tensor(df_t_norm_f).float()).detach().numpy()
y_s = np.argmax(y_s, axis=1)

#Prep Data to be loaded into the csv
df_submit= pd.DataFrame(df_t_clean[:, 0].astype(int))
df_submit['FIPS']= pd.DataFrame(df_t_clean[:, 0].astype(int))
df_submit['Result'] = y_s
df_submit = df_submit.drop(0, axis = 1)
df_submit.to_csv(r"/content/submit.csv",  index = False)

len(pd.DataFrame(y_s)[pd.DataFrame(y_s)[0] == 1])

"""<h2>Part 5: Resources and Literature Used</h2><p>"""